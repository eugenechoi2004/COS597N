{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae1dbfb0",
   "metadata": {},
   "source": [
    "# COS597N Project Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9dfe17c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import RobertaTokenizerFast, Trainer, TrainingArguments, RobertaForTokenClassification\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, log_loss, accuracy_score, matthews_corrcoef\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import re\n",
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, AutoModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ee6cfef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pickle.load(open('../Datasets/subset_featurized.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "5c64d7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pickle.load(open('../Datasets/subset_train.pkl', \"rb\"))\n",
    "df_val = pickle.load(open('../Datasets/subset_val.pkl', \"rb\"))\n",
    "df_test = pickle.load(open('../Datasets/subset_test.pkl', \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "032e181e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     477.000000\n",
       "mean      540.436059\n",
       "std       430.759875\n",
       "min        24.000000\n",
       "25%       226.000000\n",
       "50%       448.000000\n",
       "75%       713.000000\n",
       "max      2442.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_lens = pd.Series([len(seq) for seq in df_full['Sequence']])\n",
    "protein_lens.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "0a3c2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 1024\n",
    "EPOCHS = 10\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 2e-6\n",
    "BATCH_SIZE = 1\n",
    "TOKENIZER_PATH =  \"../checkpoint-final/\"\n",
    "# is this pretrained on protein sequences?\n",
    "PRETRAINED_MODEL = \"../checkpoint-final/\"\n",
    "NUM_CLASSES = 2\n",
    "SCHEDULER='cosine_with_restarts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "be61cf08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disprot_ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>full</th>\n",
       "      <th>pLDDT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>DP02004</td>\n",
       "      <td>MAENLLDGPPNPKRAKLSSPGFSANDSTDFGSLFDLENDLPDELIP...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.3606, 0.3402, 0.3392, 0.3327, 0.3693, 0.352...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>DP01306</td>\n",
       "      <td>MAELLASAGSACSWDFPRAPPSFPPPAASRGGLGGTRSFRPHRGAE...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.2828, 0.2607, 0.2338, 0.3044, 0.3376, 0.302...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DP01161</td>\n",
       "      <td>MSLICSISNEVPEHPCVSPVSNHVYERRLIEKYIAENGTDPINNQP...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5824, 0.7492, 0.8249, 0.8809, 0.9009, 0.909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DP01160</td>\n",
       "      <td>MSSPRERRPASQAPRLSRRPPAHQTSRSSPDTTAPTGSGLSNRFVN...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.4811, 0.5975, 0.4979, 0.5945, 0.5794, 0.477...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>DP01788</td>\n",
       "      <td>MDPGNENSATEAAAIIDLDPDFEPQSRPRSCTWPLPRPEIANQPSE...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.3925, 0.4244, 0.4723, 0.4422, 0.4941, 0.468...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>DP02006</td>\n",
       "      <td>MSCINLPTVLPGSPSKTRGQIQVILGPMFSGKSTELMRRVRRFQIA...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.4041, 0.4742, 0.4954, 0.5265, 0.4956, 0.548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>DP02069</td>\n",
       "      <td>MATTATMATSGSARKRLLKEEDMTKVEFETSEEVDVTPTFDTMGLR...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.4136, 0.3827, 0.3676, 0.378, 0.3997, 0.3775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>DP01876</td>\n",
       "      <td>MSARGEGAGQPSTSAQGQPAAPAPQKRGRGRPRKQQQEPTGEPSPK...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>[0.6807, 0.7178, 0.6958, 0.6563, 0.6627, 0.675...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>DP01857</td>\n",
       "      <td>MAVPETRPNHTIYINNLNEKIKKDELKKSLYAIFSQFGQILDILVS...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.3945, 0.4299, 0.524, 0.5699, 0.5804, 0.7761...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>DP01767</td>\n",
       "      <td>MGPLQGDGGPALGGADVAPRLSPVRVWPRPQAPKEPALHPMGLSLP...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.4204, 0.4144, 0.5457, 0.4025, 0.3943, 0.479...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    disprot_ID                                           Sequence  \\\n",
       "383    DP02004  MAENLLDGPPNPKRAKLSSPGFSANDSTDFGSLFDLENDLPDELIP...   \n",
       "105    DP01306  MAELLASAGSACSWDFPRAPPSFPPPAASRGGLGGTRSFRPHRGAE...   \n",
       "38     DP01161  MSLICSISNEVPEHPCVSPVSNHVYERRLIEKYIAENGTDPINNQP...   \n",
       "37     DP01160  MSSPRERRPASQAPRLSRRPPAHQTSRSSPDTTAPTGSGLSNRFVN...   \n",
       "312    DP01788  MDPGNENSATEAAAIIDLDPDFEPQSRPRSCTWPLPRPEIANQPSE...   \n",
       "..         ...                                                ...   \n",
       "385    DP02006  MSCINLPTVLPGSPSKTRGQIQVILGPMFSGKSTELMRRVRRFQIA...   \n",
       "402    DP02069  MATTATMATSGSARKRLLKEEDMTKVEFETSEEVDVTPTFDTMGLR...   \n",
       "341    DP01876  MSARGEGAGQPSTSAQGQPAAPAPQKRGRGRPRKQQQEPTGEPSPK...   \n",
       "333    DP01857  MAVPETRPNHTIYINNLNEKIKKDELKKSLYAIFSQFGQILDILVS...   \n",
       "303    DP01767  MGPLQGDGGPALGGADVAPRLSPVRVWPRPQAPKEPALHPMGLSLP...   \n",
       "\n",
       "                                                  full  \\\n",
       "383  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "105  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "38   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "37   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "312  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "..                                                 ...   \n",
       "385  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "402  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "341  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...   \n",
       "333  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "303  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                 pLDDT  \n",
       "383  [0.3606, 0.3402, 0.3392, 0.3327, 0.3693, 0.352...  \n",
       "105  [0.2828, 0.2607, 0.2338, 0.3044, 0.3376, 0.302...  \n",
       "38   [0.5824, 0.7492, 0.8249, 0.8809, 0.9009, 0.909...  \n",
       "37   [0.4811, 0.5975, 0.4979, 0.5945, 0.5794, 0.477...  \n",
       "312  [0.3925, 0.4244, 0.4723, 0.4422, 0.4941, 0.468...  \n",
       "..                                                 ...  \n",
       "385  [0.4041, 0.4742, 0.4954, 0.5265, 0.4956, 0.548...  \n",
       "402  [0.4136, 0.3827, 0.3676, 0.378, 0.3997, 0.3775...  \n",
       "341  [0.6807, 0.7178, 0.6958, 0.6563, 0.6627, 0.675...  \n",
       "333  [0.3945, 0.4299, 0.524, 0.5699, 0.5804, 0.7761...  \n",
       "303  [0.4204, 0.4144, 0.5457, 0.4025, 0.3943, 0.479...  \n",
       "\n",
       "[386 rows x 4 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c63e9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDegreeDataset(Dataset):\n",
    "\n",
    "    def __init__(self, max_length, df, tokenizer, region_type):\n",
    "        self.region_type = region_type # e.g. 'full'\n",
    "        self.df = df\n",
    "        self.seqs, self.labels, self.plddts = self.load_dataset()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def load_dataset(self):\n",
    "        seq = list(self.df['Sequence']) # list of protein sequences\n",
    "        label = list(self.df[self.region_type]) # list of list of labels\n",
    "        plddts = list(self.df['pLDDT'])\n",
    "        return seq, label, plddts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        seq = \" \".join(\"\".join(self.seqs[idx].split()))\n",
    "        seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "\n",
    "        seq_ids = self.tokenizer(seq, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        sample = {key: torch.tensor(val) for key, val in seq_ids.items()}\n",
    "        tens = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        sample['labels'] = F.pad(tens, (0, MAX_LENGTH - len(tens)))\n",
    "        plddts = torch.tensor(self.plddts[idx], dtype=torch.float)\n",
    "        sample['plddts'] = F.pad(plddts, (0, MAX_LENGTH - len(plddts)))\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "dc73e76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(TOKENIZER_PATH, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "a357d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ProteinDegreeDataset(MAX_LENGTH, df_train, tokenizer, 'full')\n",
    "# train_dataset = ProteinDegreeDataset(MAX_LENGTH, df_train., tokenizer, 'full')\n",
    "val_dataset = ProteinDegreeDataset(MAX_LENGTH, df_val, tokenizer, 'full')\n",
    "# val_dataset = ProteinDegreeDataset(MAX_LENGTH, df_val, tokenizer, 'full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f90620b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "72bc7a4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3310506/4153848418.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tens = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['plddts'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b3297980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3310506/4153848418.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tens = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 4, 21, 16,  ...,  1,  1,  1]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'labels': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'plddts': tensor([0.3562, 0.3728, 0.3850,  ..., 0.0000, 0.0000, 0.0000])}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "191c7ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3310506/4153848418.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tens = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16    130\n",
       "10    107\n",
       "18    104\n",
       "6      99\n",
       "7      89\n",
       "5      74\n",
       "15     70\n",
       "17     64\n",
       "8      48\n",
       "21     44\n",
       "12     30\n",
       "13     28\n",
       "11     28\n",
       "9      27\n",
       "22     24\n",
       "14     24\n",
       "23     11\n",
       "19     11\n",
       "20      8\n",
       "24      2\n",
       "4       1\n",
       "0       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_dataset[0]['input_ids']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588e157",
   "metadata": {},
   "source": [
    "There are 25 tokens in the vocabulary (20 amino acids and [\"unk_token\": \"[UNK]\", \"sep_token\": \"[SEP]\", \"pad_token\": \"[PAD]\", \"cls_token\": \"[CLS]\", \"mask_token\": \"[MASK]\"])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "6ff99a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3310506/4153848418.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tens = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    1024\n",
       "dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_dataset[0]['attention_mask']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c93618",
   "metadata": {},
   "source": [
    "All tokens should be attended to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bf275330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 1024 1024 1024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3310506/4153848418.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tens = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset[0]['attention_mask']), len(train_dataset[0]['input_ids']), len(train_dataset[0]['labels']), len(train_dataset[0]['plddts'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "292f4823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3310506/4153848418.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tens = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 4, 21,  6,  ...,  1,  1,  1]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0]),\n",
       " 'labels': tensor([0, 0, 0,  ..., 0, 0, 0]),\n",
       " 'plddts': tensor([0.2828, 0.2607, 0.2338,  ..., 0.0000, 0.0000, 0.0000])}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0f540",
   "metadata": {},
   "source": [
    "Finally, note that all training points are truncated to be 1024 amino acids for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "644b277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_roc_convolve(name, logits, labels, convolution):\n",
    "    convolved = np.convolve(np.array(logits).flatten(), np.array(convolution / np.sum(convolution)).flatten(), 'same')\n",
    "    p = [(1 - i, i) for i in convolved]\n",
    "    roc = [i[1] for i in p]\n",
    "    roc2 = [i[0] for i in p]\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, p)\n",
    "    roc_auc = roc_auc_score(labels, roc)\n",
    "    mcc = matthews_corrcoef(labels, p)\n",
    "    return {\n",
    "        f'precision_{name}':precision[1],\n",
    "        f'recall_{name}':recall[1],\n",
    "        f'f1_{name}':f1[1],\n",
    "        f'roc_auc_{name}':roc_auc,\n",
    "        f'mcc_{name}': mcc,\n",
    "    }\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    # creates probabilities\n",
    "    logits = softmax(logits, axis=2)\n",
    "    l = []\n",
    "    # concatenates all true labels for sequence into list\n",
    "    for j, i in enumerate(labels):\n",
    "        l = l + list(i[:len(df_val['Sequence'].iloc[j])])\n",
    "    # concatenates all prob that were predicted to be disordered into list\n",
    "    lg2 = []\n",
    "    for k, i in enumerate(logits):\n",
    "        lg2 = lg2 + [j[1] for j in i[:len(df_val['Sequence'].iloc[k])]]\n",
    "    print(np.array(lg2).shape)\n",
    "    # l is list of all concatenated true labels\n",
    "    # lg2 is list of all concatenated probabilities that corresponding residue in l is equal to 1  \n",
    "    metrics = {}\n",
    "    metrics.update(precision_recall_f1_roc_convolve('normal', lg2, l, [1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('wa5', lg2, l, [1,1,1,1,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('wa9', lg2, l, [1,1,1,1,1,1,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('wa15', lg2, l, [1]*15))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('linear5', lg2, l, [1,2,3,2,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('linear9', lg2, l, [1,2,3,4,5,4,3,2,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('linear15', lg2, l, [1,2,3,4,5,6,7,8,7,6,5,4,3,2,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('quad5', lg2, l, [1,3,9,3,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('quad9', lg2, l, [1,3,9,27,81,27,9,3,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('quad15', lg2, l, [1,3,9,27,81,243,729,2187,729,243,81,27,9,3,1]))\n",
    "    \n",
    "    logits_path = OUTPUT_DIR + '/Logits/'\n",
    "    if not os.path.isdir(logits_path):\n",
    "        os.mkdir(logits_path)\n",
    "    new_df = deepcopy(df_val)\n",
    "    new_df['Logits'] = [[i[1] for i in x] for x in list(logits)]\n",
    "    pickle.dump(new_df, open(logits_path + datetime.now().strftime(\"%H:%M:%S\"), 'wb'))\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "727848a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f'../subset_outputs/custom_baseline/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "a5837dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "81460120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBERTClassifier(nn.Module):\n",
    "    def __init__(self, path, num_classes, plddt = False):\n",
    "        super(CustomBERTClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(path)\n",
    "        self.dropout = nn.Dropout(0.1)  # Adjust dropout rate as needed\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "        self.plddt = plddt\n",
    "        if plddt:\n",
    "            self.fc = nn.Linear(self.bert.config.hidden_size + 1, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, plddts=None):\n",
    "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state\n",
    "        if plddts is not None and self.plddt:\n",
    "            pooled_output = torch.concat((pooled_output, plddts.unsqueeze(-1)), dim=2)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.fc(pooled_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b4a81a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForTokenClassification\n",
    "def model_init():\n",
    "#     model = AutoModelForTokenClassification.from_pretrained(PRETRAINED_MODEL, num_labels=NUM_CLASSES)\n",
    "    model = CustomBERTClassifier(PRETRAINED_MODEL, NUM_CLASSES)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0e20b288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../checkpoint-final/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = model_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "7cb96d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomBERTClassifier(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(35, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(1026, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "94d6330a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/byw2/.conda/envs/dr-bert-env/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize optimizer and training parameters\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "num_epochs = EPOCHS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "2dd6596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')\n",
    "best_model_path = OUTPUT_DIR + 'best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4df116b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../subset_outputs/custom_baseline/best_model.pth'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6b0a6a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "08a05c73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/386 [00:00<?, ?it/s]/tmp/ipykernel_3310506/4153848418.py:28: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  tens = torch.tensor(self.labels[idx], dtype=torch.long)\n",
      "Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.3199656251335391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.25361258288224536\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.22530013884519048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.234670619169871\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.21440623960230942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.23348179956277212\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.20997017436694604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.22492478291193643\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1937767312393905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.21033368508021036\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.17783353374933178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20537668466567993\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.1703557892379211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20348040262858072\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.16779330016688052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20256341000398\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.16711957783587855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20211215317249298\n",
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [00:12<00:00, 30.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.16547900999515014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.20025297502676645\n",
      "Best model saved.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # set model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    # for each epoch\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        outputs = outputs.view(-1, 2)\n",
    "        labels = labels.view(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    average_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(average_loss)\n",
    "    print(f'Training Loss: {average_loss}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc='Validation'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            preds = outputs.view(-1, 2)\n",
    "            labs = labels.view(-1)\n",
    "            val_loss = criterion(preds, labs)\n",
    "            total_val_loss += val_loss.item()\n",
    "            \n",
    "#     metrics = compute_metrics((outputs.cpu().numpy(), labels.cpu().numpy()))\n",
    "    average_val_loss = total_val_loss / len(val_loader)\n",
    "    val_losses.append(average_val_loss)\n",
    "    print(f'Validation Loss: {average_val_loss}')\n",
    "    \n",
    "    # Save the best model\n",
    "    if average_val_loss < best_val_loss:\n",
    "        best_val_loss = average_val_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print('Best model saved.')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "13361441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at ../checkpoint-final/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomBERTClassifier(\n",
       "  (bert): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(35, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(1026, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ft_model = CustomBERTClassifier(PRETRAINED_MODEL, NUM_CLASSES)\n",
    "best_ft_model.load_state_dict(torch.load(best_model_path))\n",
    "best_ft_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "014d0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle('../Datasets/subset_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "f6bea838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_f1_roc_convolve(name, logits, labels, convolution):\n",
    "    logits = [i[1] for i in logits]\n",
    "    convolved = np.convolve(np.array(logits).flatten(), np.array(convolution / np.sum(convolution).flatten()), 'same')\n",
    "    p = [(1 - i, i) for i in convolved]\n",
    "    roc = [i[1] for i in p]\n",
    "    print(len(p))\n",
    "    p = np.argmax(p, axis=-1)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, p)\n",
    "    roc_auc = roc_auc_score(labels, roc)\n",
    "    mcc = matthews_corrcoef(labels, p)\n",
    "    return {\n",
    "        f'precision_{name}':precision[1],\n",
    "        f'recall_{name}':recall[1],\n",
    "        f'f1_{name}':f1[1],\n",
    "        f'roc_auc_{name}':roc_auc,\n",
    "        f'MCC_{name}':mcc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4ddcd0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits, labels):\n",
    "    logits = softmax(logits, axis=1)\n",
    "    print(logits.shape)\n",
    "    print(labels.shape)\n",
    "    l = labels\n",
    "#     l = []\n",
    "#     for j, i in enumerate(labels):\n",
    "#         l = l + list(i)\n",
    "#     print(len(l), len(logits))\n",
    "    lg2 = logits\n",
    "    print(lg2.shape)\n",
    "    metrics = {}\n",
    "    metrics.update(precision_recall_f1_roc_convolve('normal', lg2, l, [1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('wa5', lg2, l, [1,1,1,1,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('wa9', lg2, l, [1,1,1,1,1,1,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('wa15', lg2, l, [1]*15))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('linear5', lg2, l, [1,2,3,2,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('linear9', lg2, l, [1,2,3,4,5,4,3,2,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('linear15', lg2, l, [1,2,3,4,5,6,7,8,7,6,5,4,3,2,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('quad5', lg2, l, [1,3,9,3,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('quad9', lg2, l, [1,3,9,27,81,27,9,3,1]))\n",
    "#     metrics.update(precision_recall_f1_roc_convolve('quad15', lg2, l, [1,3,9,27,81,243,729,2187,729,243,81,27,9,3,1]))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f30194db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_out(encoded, model):\n",
    "    \"\"\"Given encoding, pass through model to get logits. Returns logits.\"\"\"\n",
    "    encoded.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d968cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(sent, tokenizer, model):\n",
    "    \"\"\"Returns logits.\"\"\"\n",
    "    encoded = tokenizer.encode_plus(sent, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    out = model_out(encoded, model)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "5459fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "labs = []\n",
    "for index, row in df_test.iterrows():\n",
    "    seq = row['Sequence']\n",
    "    lab = list(row['full'])\n",
    "    word_embedding = get_word_vector(seq[:min(1024, len(seq))], tokenizer, best_ft_model)\n",
    "    word_embedding = word_embedding[0]\n",
    "    word_embedding = word_embedding[1:-1]\n",
    "    word_embedding = word_embedding.cpu()\n",
    "    word_embedding_full = np.squeeze(word_embedding.numpy())\n",
    "#     print(word_embedding.shape)\n",
    "    if len(seq) > 2044:\n",
    "        for i in range(1022, len(seq) - 1022, 1022):\n",
    "            word_embedding = get_word_vector(seq[i:i+1022], tokenizer, best_ft_model)\n",
    "            word_embedding = word_embedding[0]\n",
    "            word_embedding = word_embedding[1:-1]\n",
    "            word_embedding = word_embedding.cpu()\n",
    "            word_embedding = np.squeeze(word_embedding.numpy())\n",
    "            word_embedding_full = np.concatenate([word_embedding_full, word_embedding], axis=0)\n",
    "    if len(seq) > 1024:\n",
    "        word_embedding = get_word_vector(seq[len(seq) - 1022:len(seq)], tokenizer, best_ft_model)\n",
    "        word_embedding = word_embedding[0]\n",
    "        word_embedding = word_embedding[1:-1]\n",
    "        word_embedding = word_embedding.cpu()\n",
    "        word_embedding = np.squeeze(word_embedding.numpy())\n",
    "        overlap_amount = 1022 - (len(seq) % 1022)\n",
    "        overlap = word_embedding_full[(-1 * overlap_amount):]\n",
    "        word_embedding_full[(-1 * overlap_amount):] = (overlap + word_embedding[:overlap_amount]) / 2\n",
    "        end_chunk = word_embedding[overlap_amount:]\n",
    "        word_embedding_full = np.concatenate([word_embedding_full, end_chunk], axis=0)\n",
    "#     print(word_embedding_full.shape, len(seq))\n",
    "    Xs.append(word_embedding_full)\n",
    "    labs.append(lab[:len(seq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "607f6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = np.concatenate(Xs)\n",
    "labs = np.concatenate(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f235a2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22980,)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f1fd5977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22980, 2)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d5cad153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22980, 2)\n",
      "(22980,)\n",
      "(22980, 2)\n",
      "22980\n"
     ]
    }
   ],
   "source": [
    "metrics = compute_metrics(Xs, labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "a2493cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision_normal': 0.4345718901453958,\n",
       " 'recall_normal': 0.21734446539186641,\n",
       " 'f1_normal': 0.28976660682226213,\n",
       " 'roc_auc_normal': 0.7753798237871533,\n",
       " 'MCC_normal': 0.21992059569829922}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4eb893ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(1, 11)), train_losses)\n",
    "plt.plot(list(range(1, 11)), val_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "141b74d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../subset_outputs/custom_baseline/'"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "71378dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    "    'train': train_losses,\n",
    "    'val': val_losses\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "dbdd7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{OUTPUT_DIR}losses.pkl', 'wb') as f:\n",
    "    pickle.dump(losses, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "d3f78c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data (deserialize)\n",
    "# with open(f'{OUTPUT_DIR}losses.pkl', 'rb') as f:\n",
    "#     tmp = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aede1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr-bert-env [~/.conda/envs/dr-bert-env/]",
   "language": "python",
   "name": "conda_dr-bert-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
